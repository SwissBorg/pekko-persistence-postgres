# Copyright 2016 Dennis Vriend
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

pekko-persistence-postgres {

  # If set to true event deletion is performed as a soft, logical delete. Events are kept in the journal and are sill
  # delivered in queries. Otherwise, a hard delete will be performed.
  #
  # Note that even when configured for hard deletes, the last event is kept as a logical delete.
  # This is necessary because we must keep track of the highest sequence number that was ever used on a
  # given persistent actor. However, this last event will be 'invisible' it won't be ever replay nor delivered on queries.
  #
  # This property affects postgres-journal.logicalDelete and postgres-read-journal.includeLogicallyDeleted.
  #
  logicalDeletion.enable = true

  database-provider-fqcn = "org.apache.pekko.persistence.postgres.db.DefaultSlickDatabaseProvider"

  shared-databases {
    // Shared databases can be defined here.
    // This reference config contains a partial example if a shared database which is enabled by configuring "slick" as the shared db
    // this example is ignored by default as long as no profile is default
    slick {

      # This property indicates which profile must be used by Slick.
      # Possible values are: slick.jdbc.PostgresProfile$
      # (uncomment and set the property below to match your needs)
      # profile = "slick.jdbc.PostgresProfile$"

      db {
        connectionPool = "HikariCP"

        # The JDBC URL for the chosen database
        # (uncomment and set the property below to match your needs)
        # url = "jdbc:postgresql://localhost:5432/pekko-plugin"

        # The database username
        # (uncomment and set the property below to match your needs)
        # user = "pekko-plugin"

        # The username's password
        # (uncomment and set the property below to match your needs)
        # password = "pekko-plugin"

        # hikariCP settings; see: https://github.com/brettwooldridge/HikariCP
        # Slick will use an async executor with a fixed size queue of 10.000 objects
        # The async executor is a connection pool for asynchronous execution of blocking I/O actions.
        # This is used for the asynchronous query execution API on top of blocking back-ends like JDBC.
        queueSize = 10000 // number of objects that can be queued by the async exector

        # This property controls the maximum number of milliseconds that a client (that's you) will wait for a connection
        # from the pool. If this time is exceeded without a connection becoming available, a SQLException will be thrown.
        # 1000ms is the minimum value. Default: 180000 (3 minutes)
        connectionTimeout = 180000

        # This property controls the maximum amount of time that a connection will be tested for aliveness.
        # This value must be less than the connectionTimeout. The lowest accepted validation timeout is 1000ms (1 second). Default: 5000
        validationTimeout = 5000

        # 10 minutes: This property controls the maximum amount of time that a connection is allowed to sit idle in the pool.
        # Whether a connection is retired as idle or not is subject to a maximum variation of +30 seconds, and average variation
        # of +15 seconds. A connection will never be retired as idle before this timeout. A value of 0 means that idle connections
        # are never removed from the pool. Default: 600000 (10 minutes)
        idleTimeout = 600000

        # 30 minutes: This property controls the maximum lifetime of a connection in the pool. When a connection reaches this timeout
        # it will be retired from the pool, subject to a maximum variation of +30 seconds. An in-use connection will never be retired,
        # only when it is closed will it then be removed. We strongly recommend setting this value, and it should be at least 30 seconds
        # less than any database-level connection timeout. A value of 0 indicates no maximum lifetime (infinite lifetime),
        # subject of course to the idleTimeout setting. Default: 1800000 (30 minutes)
        maxLifetime = 1800000

        # This property controls the amount of time that a connection can be out of the pool before a message is logged indicating a
        # possible connection leak. A value of 0 means leak detection is disabled.
        # Lowest acceptable value for enabling leak detection is 2000 (2 secs). Default: 0
        leakDetectionThreshold = 0

        # ensures that the database does not get dropped while we are using it
        keepAliveConnection = on

        # See some tips on thread/connection pool sizing on https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing
        # Keep in mind that the number of threads must equal the maximum number of connections.
        numThreads = 20
        maxConnections = 20
        minConnections = 20
      }
    }
  }
}

# the pekko-persistence-journal in use
postgres-journal {
  class = "org.apache.pekko.persistence.postgres.journal.PostgresAsyncWriteJournal"

  tables {
    journal {
      # Used by org.apache.pekko.persistence.postgres.journal.dao.NestedPartitionsJournalDao
      # and org.apache.pekko.persistence.postgres.journal.dao.PartitionedJournalDao
      partitions {
        # The size of a single partition
        size: 10000000
        # Partition name prefix
        prefix: "j"
      }
      tableName = "journal"
      schemaName = ""
      columnNames {
        ordering = "ordering"
        deleted = "deleted"
        persistenceId = "persistence_id"
        sequenceNumber = "sequence_number"
        created = "created"
        tags = "tags"
        message = "message"
        metadata = "metadata"
      }
    }
    # Used to hold journal information that can be used to speed up queries
    journalMetadata {
      tableName = "journal_metadata"
      schemaName = ""
      columnNames = {
        persistenceId = "persistence_id"
        maxSequenceNumber = "max_sequence_number"
        maxOrdering = "max_ordering"
        minOrdering = "min_ordering"
      }
    }
    tags {
      tableName = "tags"
      schameName = ""
      columnNames {
        id = "id"
        name = "name"
      }
    }
  }

  # Replace with "org.apache.pekko.persistence.postgres.journal.dao.NestedPartitionsJournalDao"
  # or "org.apache.pekko.persistence.postgres.journal.dao.PartitionedJournalDao" in order to enable
  # partitioning.
  dao = "org.apache.pekko.persistence.postgres.journal.dao.FlatJournalDao"

  # Confguration for org.apache.pekko.persistence.postgres.tag.TagIdResolver
  tags {
    # The timeout after unused tag is removed from the TagIdResolver's cache
    cacheTtl = 1 hour
    # Used in case of multiple sessions trying to add the same tag-label-to-id mapping at the same time.
    insertionRetryAttempts = 1
  }

  # The size of the buffer used when queueing up events for batch writing. This number must be bigger then the number
  # of events that may be written concurrently. In other words this number must be bigger than the number of persistent
  # actors that are actively peristing at the same time.
  bufferSize = 1000
  # The maximum size of the batches in which journal rows will be inserted
  batchSize = 400
  # The maximum size of the batches in which journal rows will be read when recovering
  replayBatchSize = 400
  # The maximum number of batch-inserts that may be running concurrently
  parallelism = 8

  # Only mark as deleted. If false, delete physically
  # should not be configured directly, but through property pekko-persistence-postgres.logicalDelete.enable
  # in order to keep consistent behavior over write/read sides
  logicalDelete = ${pekko-persistence-postgres.logicalDeletion.enable}

  # This setting can be used to configure usage of a shared database.
  # To disable usage of a shared database, set to null or an empty string.
  # When set to a non empty string, this setting does two things:
  # - The actor which manages the write-journal will not automatically close the db when the actor stops (since it is shared)
  # - If pekko-persistence-postgres.database-provider-fqcn is set to org.apache.pekko.persistence.postgres.db.DefaultSlickDatabaseProvider
  #   then the shared database with the given name will be used. (shared databases are configured as part of pekko-persistence-postgres.shared-databases)
  #   Please note that the database will only be shared with the other journals if the use-shared-db is also set
  #   to the same value for these other journals.
  use-shared-db = null

  # This setting can be used to enable the usage of the data being stored
  # at the journal_metadata table, in order to speed up some queries that would
  # solely use the journal table.
  # In case the metadata table does not hold the required information (not available yet),
  # the logic fallback to the journal-only queries.
  # This setting is disabled by default.
  use-journal-metadata = false

  slick {

    db {
      connectionPool = "HikariCP"

      # The JDBC URL for the chosen database
      # (uncomment and set the property below to match your needs)
      # url = "jdbc:postgresql://localhost:5432/pekko-plugin"

      # The database username
      # (uncomment and set the property below to match your needs)
      # user = "pekko-plugin"

      # The username's password
      # (uncomment and set the property below to match your needs)
      # password = "pekko-plugin"

      # hikariCP settings; see: https://github.com/brettwooldridge/HikariCP
      # Slick will use an async executor with a fixed size queue of 10.000 objects
      # The async executor is a connection pool for asynchronous execution of blocking I/O actions.
      # This is used for the asynchronous query execution API on top of blocking back-ends like JDBC.
      queueSize = 10000 // number of objects that can be queued by the async exector

      # This property controls the maximum number of milliseconds that a client (that's you) will wait for a connection
      # from the pool. If this time is exceeded without a connection becoming available, a SQLException will be thrown.
      # 1000ms is the minimum value. Default: 180000 (3 minutes)
      connectionTimeout = 180000

      # This property controls the maximum amount of time that a connection will be tested for aliveness.
      # This value must be less than the connectionTimeout. The lowest accepted validation timeout is 1000ms (1 second). Default: 5000
      validationTimeout = 5000

      # 10 minutes: This property controls the maximum amount of time that a connection is allowed to sit idle in the pool.
      # Whether a connection is retired as idle or not is subject to a maximum variation of +30 seconds, and average variation
      # of +15 seconds. A connection will never be retired as idle before this timeout. A value of 0 means that idle connections
      # are never removed from the pool. Default: 600000 (10 minutes)
      idleTimeout = 600000

      # 30 minutes: This property controls the maximum lifetime of a connection in the pool. When a connection reaches this timeout
      # it will be retired from the pool, subject to a maximum variation of +30 seconds. An in-use connection will never be retired,
      # only when it is closed will it then be removed. We strongly recommend setting this value, and it should be at least 30 seconds
      # less than any database-level connection timeout. A value of 0 indicates no maximum lifetime (infinite lifetime),
      # subject of course to the idleTimeout setting. Default: 1800000 (30 minutes)
      maxLifetime = 1800000

      # This property controls the amount of time that a connection can be out of the pool before a message is logged indicating a
      # possible connection leak. A value of 0 means leak detection is disabled.
      # Lowest acceptable value for enabling leak detection is 2000 (2 secs). Default: 0
      leakDetectionThreshold = 0

      # ensures that the database does not get dropped while we are using it
      keepAliveConnection = on

      # See some tips on thread/connection pool sizing on https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing
      # Keep in mind that the number of threads must equal the maximum number of connections.
      numThreads = 20
      maxConnections = 20
      minConnections = 20
    }
  }
}

# the pekko-persistence-snapshot-store in use
postgres-snapshot-store {
  class = "org.apache.pekko.persistence.postgres.snapshot.PostgresSnapshotStore"

  tables {
    snapshot {
      tableName = "snapshot"
      schemaName = ""
      columnNames {
        persistenceId = "persistence_id"
        sequenceNumber = "sequence_number"
        created = "created"
        snapshot = "snapshot"
        metadata = "metadata"
      }
    }
  }

  # This setting can be used to configure usage of a shared database.
  # To disable usage of a shared database, set to null or an empty string.
  # When set to a non empty string, this setting does two things:
  # - The actor which manages the snapshot-journal will not automatically close the db when the actor stops (since it is shared)
  # - If pekko-persistence-postgres.database-provider-fqcn is set to org.apache.pekko.persistence.postgres.db.DefaultSlickDatabaseProvider
  #   then the shared database with the given name will be used. (shared databases are configured as part of pekko-persistence-postgres.shared-databases)
  #   Please note that the database will only be shared with the other journals if the use-shared-db is also set
  #   to the same value for these other journals.
  use-shared-db = null

  dao = "org.apache.pekko.persistence.postgres.snapshot.dao.ByteArraySnapshotDao"

  slick {

    db {
      connectionPool = "HikariCP"

      # The JDBC URL for the chosen database
      # (uncomment and set the property below to match your needs)
      # url = "jdbc:postgresql://localhost:5432/pekko-plugin"

      # The database username
      # (uncomment and set the property below to match your needs)
      # user = "pekko-plugin"

      # The username's password
      # (uncomment and set the property below to match your needs)
      # password = "pekko-plugin"

      # hikariCP settings; see: https://github.com/brettwooldridge/HikariCP
      # Slick will use an async executor with a fixed size queue of 10.000 objects
      # The async executor is a connection pool for asynchronous execution of blocking I/O actions.
      # This is used for the asynchronous query execution API on top of blocking back-ends like JDBC.
      queueSize = 10000 // number of objects that can be queued by the async exector

      # This property controls the maximum number of milliseconds that a client (that's you) will wait for a connection
      # from the pool. If this time is exceeded without a connection becoming available, a SQLException will be thrown.
      # 1000ms is the minimum value. Default: 180000 (3 minutes)
      connectionTimeout = 180000

      # This property controls the maximum amount of time that a connection will be tested for aliveness.
      # This value must be less than the connectionTimeout. The lowest accepted validation timeout is 1000ms (1 second). Default: 5000
      validationTimeout = 5000

      # 10 minutes: This property controls the maximum amount of time that a connection is allowed to sit idle in the pool.
      # Whether a connection is retired as idle or not is subject to a maximum variation of +30 seconds, and average variation
      # of +15 seconds. A connection will never be retired as idle before this timeout. A value of 0 means that idle connections
      # are never removed from the pool. Default: 600000 (10 minutes)
      idleTimeout = 600000

      # 30 minutes: This property controls the maximum lifetime of a connection in the pool. When a connection reaches this timeout
      # it will be retired from the pool, subject to a maximum variation of +30 seconds. An in-use connection will never be retired,
      # only when it is closed will it then be removed. We strongly recommend setting this value, and it should be at least 30 seconds
      # less than any database-level connection timeout. A value of 0 indicates no maximum lifetime (infinite lifetime),
      # subject of course to the idleTimeout setting. Default: 1800000 (30 minutes)
      maxLifetime = 1800000

      # This property controls the amount of time that a connection can be out of the pool before a message is logged indicating a
      # possible connection leak. A value of 0 means leak detection is disabled.
      # Lowest acceptable value for enabling leak detection is 2000 (2 secs). Default: 0
      leakDetectionThreshold = 0

      # ensures that the database does not get dropped while we are using it
      keepAliveConnection = on

      # See some tips on thread/connection pool sizing on https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing
      # Keep in mind that the number of threads must equal the maximum number of connections.
      numThreads = 20
      maxConnections = 20
      minConnections = 20
    }
  }
}

# the pekko-persistence-query provider in use
postgres-read-journal {
  class = "org.apache.pekko.persistence.postgres.query.PostgresReadJournalProvider"

  # Absolute path to the write journal plugin configuration section.
  # Read journal uses event adapters from the write plugin
  # to adapt events.
  write-plugin = "postgres-journal"

  # New events are retrieved (polled) with this interval.
  refresh-interval = "1s"

  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = "500"

  # If enabled, automatically close the database connection when the actor system is terminated
  add-shutdown-hook = true

  # This setting can be used to configure usage of a shared database.
  # To disable usage of a shared database, set to null or an empty string.
  # This setting only has effect if pekko-persistence-postgres.database-provider-fqcn is set to
  # org.apache.pekko.persistence.postgres.db.DefaultSlickDatabaseProvider. When this setting is set to a non empty string
  # then the shared database with the given name will be used. (shared databases are configured as part of pekko-persistence-postgres.shared-databases)
  # Please note that the database will only be shared with the other journals if the use-shared-db is also set
  # to the same value for these other journals.
  use-shared-db = null

  # This setting can be used to enable the usage of the data being stored
  # at the journal_metadata table, in order to speed up some queries that would
  # solely use the journal table.
  # In case the metadata table does not hold the required information (not available yet),
  # the logic fallback to the journal-only queries.
  # This setting is disabled by default.
  use-journal-metadata = false


  # Replace with "org.apache.pekko.persistence.postgres.query.dao.PartitionedReadJournalDao" in order to leverage dedicated queries to
  # partitioned journal.
  dao = "org.apache.pekko.persistence.postgres.query.dao.FlatReadJournalDao"

  # Configuration for org.apache.pekko.persistence.postgres.tag.TagIdResolver
  tags {
    # The timeout after unused tag is removed from the TagIdResolver's cache
    cacheTtl = 1 hour
  }

  # if true, queries will include logically deleted events
  # should not be configured directly, but through property pekko-persistence-postgres.logicalDelete.enable
  # in order to keep consistent behavior over write/read sides
  includeLogicallyDeleted = ${pekko-persistence-postgres.logicalDeletion.enable}

  # Settings for determining if ids (ordering column) in the journal are out of sequence.
  journal-sequence-retrieval {
    # The maximum number of ids that will be retrieved in each batch
    batch-size = 10000
    # In case a number in the sequence is missing, this is the amount of retries that will be done to see
    # if the number is still found. Note that the time after which a number in the sequence is assumed missing is
    # equal to maxTries * queryDelay
    # (maxTries may not be zero)
    max-tries = 10
    # How often the actor will query for new data
    query-delay = 1 second
    # The maximum backoff time before trying to query again in case of database failures
    max-backoff-query-delay = 1 minute
    # The ask timeout to use when querying the journal sequence actor, the actor should normally respond very quickly,
    # since it always replies with its current internal state
    ask-timeout = 1 second
  }

  tables {
    journal {
      tableName = "journal"
      schemaName = ""
      columnNames {
        ordering = "ordering"
        persistenceId = "persistence_id"
        sequenceNumber = "sequence_number"
        created = "created"
        tags = "tags"
        message = "message"
      }
    }
    # Used to hold journal information that can be used to speed up queries
    journalMetadata {
      tableName = "journal_metadata"
      schemaName = ""
      columnNames = {
        persistenceId = "persistence_id"
        maxSequenceNumber = "max_sequence_number"
        maxOrdering = "max_ordering"
        minOrdering = "min_ordering"
      }
    }
    tags {
      tableName = "tags"
      schameName = ""
      columnNames {
        id = "id"
        name = "name"
      }
    }
  }

  slick {

    db {
      connectionPool = "HikariCP"

      # The JDBC URL for the chosen database
      # (uncomment and set the property below to match your needs)
      # url = "jdbc:postgresql://localhost:5432/pekko-plugin"

      # The database username
      # (uncomment and set the property below to match your needs)
      # user = "pekko-plugin"

      # The username's password
      # (uncomment and set the property below to match your needs)
      # password = "pekko-plugin"

      # hikariCP settings; see: https://github.com/brettwooldridge/HikariCP
      # Slick will use an async executor with a fixed size queue of 10.000 objects
      # The async executor is a connection pool for asynchronous execution of blocking I/O actions.
      # This is used for the asynchronous query execution API on top of blocking back-ends like JDBC.
      queueSize = 10000 // number of objects that can be queued by the async exector

      # This property controls the maximum number of milliseconds that a client (that's you) will wait for a connection
      # from the pool. If this time is exceeded without a connection becoming available, a SQLException will be thrown.
      # 1000ms is the minimum value. Default: 180000 (3 minutes)
      connectionTimeout = 180000

      # This property controls the maximum amount of time that a connection will be tested for aliveness.
      # This value must be less than the connectionTimeout. The lowest accepted validation timeout is 1000ms (1 second). Default: 5000
      validationTimeout = 5000

      # 10 minutes: This property controls the maximum amount of time that a connection is allowed to sit idle in the pool.
      # Whether a connection is retired as idle or not is subject to a maximum variation of +30 seconds, and average variation
      # of +15 seconds. A connection will never be retired as idle before this timeout. A value of 0 means that idle connections
      # are never removed from the pool. Default: 600000 (10 minutes)
      idleTimeout = 600000

      # 30 minutes: This property controls the maximum lifetime of a connection in the pool. When a connection reaches this timeout
      # it will be retired from the pool, subject to a maximum variation of +30 seconds. An in-use connection will never be retired,
      # only when it is closed will it then be removed. We strongly recommend setting this value, and it should be at least 30 seconds
      # less than any database-level connection timeout. A value of 0 indicates no maximum lifetime (infinite lifetime),
      # subject of course to the idleTimeout setting. Default: 1800000 (30 minutes)
      maxLifetime = 1800000

      # This property controls the amount of time that a connection can be out of the pool before a message is logged indicating a
      # possible connection leak. A value of 0 means leak detection is disabled.
      # Lowest acceptable value for enabling leak detection is 2000 (2 secs). Default: 0
      leakDetectionThreshold = 0

      # ensures that the database does not get dropped while we are using it
      keepAliveConnection = on

      # See some tips on thread/connection pool sizing on https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing
      # Keep in mind that the number of threads must equal the maximum number of connections.
      numThreads = 20
      maxConnections = 20
      minConnections = 20
    }
  }
}
